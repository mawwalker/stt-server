#!/usr/bin/env python3
"""
WebSocketå®¢æˆ·ç«¯ï¼Œç”¨äºè°ƒç”¨è¯­éŸ³è¯†åˆ«æœåŠ¡ç«¯
æ”¯æŒéº¦å…‹é£å®æ—¶æ¨ç†å’Œæ–‡ä»¶æ¨ç†
"""
import asyncio
import websockets
import numpy as np
import sys
import os
# import logging
from loguru import logger
import argparse
import json
from pathlib import Path
import time

try:
    import librosa
    import soundfile as sf
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    print("Warning: librosaä¸å¯ç”¨ï¼Œåªæ”¯æŒWAVæ–‡ä»¶æ ¼å¼")

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False
    print("Warning: pyaudioä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨éº¦å…‹é£")

import wave


def load_audio_file(audio_file_path, target_sr=16000):
    """
    åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    è¿”å›: (audio_data, sample_rate) å…¶ä¸­audio_dataæ˜¯å•å£°é“float32æ•°æ®ï¼ŒèŒƒå›´[-1, 1]
    """
    file_path = Path(audio_file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
    
    file_ext = file_path.suffix.lower()
    logger.info(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶: {file_path} (æ ¼å¼: {file_ext})")
    
    # ä¼˜å…ˆä½¿ç”¨librosaï¼ˆè´¨é‡æœ€å¥½ï¼Œæ”¯æŒæœ€å¤šæ ¼å¼ï¼‰
    if LIBROSA_AVAILABLE:
        try:
            logger.info("ä½¿ç”¨librosaåŠ è½½éŸ³é¢‘...")
            audio_data, sample_rate = librosa.load(
                audio_file_path, 
                sr=target_sr,  # è‡ªåŠ¨é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
                mono=True,     # è½¬æ¢ä¸ºå•å£°é“
                dtype=np.float32
            )
            logger.info(f"librosaåŠ è½½æˆåŠŸ: {sample_rate}Hz, {len(audio_data)}ä¸ªé‡‡æ ·ç‚¹, èŒƒå›´: [{audio_data.min():.3f}, {audio_data.max():.3f}]")
            return audio_data, sample_rate
        except Exception as e:
            logger.error(f"librosaåŠ è½½å¤±è´¥: {e}")
    
    # å›é€€åˆ°waveåº“å¤„ç†WAVæ–‡ä»¶
    if file_ext == '.wav':
        try:
            logger.info("ä½¿ç”¨waveåº“åŠ è½½WAVæ–‡ä»¶...")
            with wave.open(audio_file_path, 'rb') as wav_file:
                frames = wav_file.readframes(wav_file.getnframes())
                sample_rate = wav_file.getframerate()
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()
                
            logger.info(f"WAVæ–‡ä»¶ä¿¡æ¯: {sample_rate}Hz, {channels}å£°é“, {sample_width}å­—èŠ‚/é‡‡æ ·")
            
            # è½¬æ¢ä¸ºfloat32æ ¼å¼
            if sample_width == 2:  # 16-bit
                audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
            elif sample_width == 4:  # 32-bit
                audio_data = np.frombuffer(frames, dtype=np.int32).astype(np.float32) / 2147483648.0
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·ä½å®½: {sample_width}")
                
            # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“
            if channels == 2:
                audio_data = audio_data.reshape(-1, 2).mean(axis=1)
                
            # å¦‚æœéœ€è¦é‡é‡‡æ ·
            if sample_rate != target_sr:
                if LIBROSA_AVAILABLE:
                    audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=target_sr)
                    sample_rate = target_sr
                else:
                    # ç®€å•é™é‡‡æ ·
                    step = max(1, sample_rate // target_sr)
                    audio_data = audio_data[::step]
                    sample_rate = target_sr
                    
            logger.info(f"WAVå¤„ç†å®Œæˆ: {sample_rate}Hz, {len(audio_data)}ä¸ªé‡‡æ ·ç‚¹, èŒƒå›´: [{audio_data.min():.3f}, {audio_data.max():.3f}]")
            return audio_data, sample_rate
            
        except Exception as e:
            logger.error(f"WAVæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {file_ext}. æ”¯æŒçš„æ ¼å¼: WAV (æ¨èå®‰è£…librosaä»¥æ”¯æŒæ›´å¤šæ ¼å¼)")


class MicrophoneStream:
    """å®æ—¶éº¦å…‹é£éŸ³é¢‘æµ"""
    
    def __init__(self, sample_rate=16000, chunk_size=1024):
        if not PYAUDIO_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…pyaudioæ‰èƒ½ä½¿ç”¨éº¦å…‹é£")
        
        self.target_sample_rate = sample_rate
        self.actual_sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.format = pyaudio.paFloat32
        self.channels = 1
        self.p = None
        self.stream = None
        self.device_index = None
        
    def _find_best_device(self):
        """æ‰¾åˆ°æœ€ä½³çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
        # ä¼˜å…ˆçº§ï¼špipewire > pulse > USBéŸ³é¢‘è®¾å¤‡ > å…¶ä»–
        device_priorities = [
            ("pipewire", 100),
            ("pulse", 90),
            ("Razer Seiren", 80),
            ("USB Audio", 70),
            ("Microphone", 60),
            ("Line Input", 50)
        ]
        
        best_device = None
        best_score = -1
        default_device = self.p.get_default_input_device_info()
        
        logger.info("å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
        for i in range(self.p.get_device_count()):
            info = self.p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                logger.info(f"  {i}: {info['name']} (æœ€å¤§è¾“å…¥å£°é“: {info['maxInputChannels']}, é»˜è®¤é‡‡æ ·ç‡: {info['defaultSampleRate']})")
                
                # è®¡ç®—è®¾å¤‡è¯„åˆ†
                score = 0
                for keyword, priority in device_priorities:
                    if keyword.lower() in info['name'].lower():
                        score = priority
                        break
                
                # å¦‚æœæ˜¯é»˜è®¤è®¾å¤‡ï¼ŒåŠ åˆ†
                if i == default_device['index']:
                    score += 10
                    logger.info(f"    ^ è¿™æ˜¯ç³»ç»Ÿé»˜è®¤è¾“å…¥è®¾å¤‡")
                
                if score > best_score:
                    best_score = score
                    best_device = i
        
        return best_device, default_device
        
    def _test_sample_rate(self, device_index, sample_rate):
        """æµ‹è¯•è®¾å¤‡æ˜¯å¦æ”¯æŒæŒ‡å®šé‡‡æ ·ç‡"""
        try:
            # å°è¯•æ‰“å¼€æµä½†ä¸å¯åŠ¨
            test_stream = self.p.open(
                format=self.format,
                channels=self.channels,
                rate=sample_rate,
                input=True,
                input_device_index=device_index,
                frames_per_buffer=self.chunk_size,
                start=False
            )
            test_stream.close()
            return True
        except Exception:
            return False
            
    def _find_best_sample_rate(self, device_index):
        """ä¸ºè®¾å¤‡æ‰¾åˆ°æœ€ä½³é‡‡æ ·ç‡"""
        # å¸¸è§é‡‡æ ·ç‡ï¼Œä¼˜å…ˆé€‰æ‹©ç›®æ ‡é‡‡æ ·ç‡
        sample_rates = [self.target_sample_rate, 44100, 48000, 22050, 32000, 8000]
        
        for rate in sample_rates:
            if self._test_sample_rate(device_index, rate):
                logger.info(f"è®¾å¤‡æ”¯æŒé‡‡æ ·ç‡: {rate}Hz")
                return rate
        
        # å¦‚æœéƒ½ä¸æ”¯æŒï¼Œå°è¯•è®¾å¤‡çš„é»˜è®¤é‡‡æ ·ç‡
        try:
            device_info = self.p.get_device_info_by_index(device_index)
            default_rate = int(device_info['defaultSampleRate'])
            if self._test_sample_rate(device_index, default_rate):
                logger.info(f"ä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡: {default_rate}Hz")
                return default_rate
        except Exception:
            pass
        
        raise RuntimeError("æ— æ³•æ‰¾åˆ°æ”¯æŒçš„é‡‡æ ·ç‡")
        
    def start(self):
        """å¼€å§‹å½•éŸ³"""
        self.p = pyaudio.PyAudio()
        
        # æ‰¾åˆ°æœ€ä½³è®¾å¤‡
        best_device, default_device = self._find_best_device()
        
        if best_device is not None:
            self.device_index = best_device
            device_name = self.p.get_device_info_by_index(best_device)['name']
            logger.info(f"é€‰æ‹©éŸ³é¢‘è®¾å¤‡: {device_name} (ç´¢å¼•: {best_device})")
        else:
            self.device_index = default_device['index']
            logger.info(f"ä½¿ç”¨é»˜è®¤éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {self.device_index})")
        
        # æ‰¾åˆ°æœ€ä½³é‡‡æ ·ç‡
        try:
            self.actual_sample_rate = self._find_best_sample_rate(self.device_index)
        except RuntimeError as e:
            logger.error(f"é‡‡æ ·ç‡é…ç½®å¤±è´¥: {e}")
            # å°è¯•ä½¿ç”¨é»˜è®¤è®¾å¤‡
            if self.device_index != default_device['index']:
                logger.info("å°è¯•ä½¿ç”¨é»˜è®¤è®¾å¤‡...")
                self.device_index = default_device['index']
                try:
                    self.actual_sample_rate = self._find_best_sample_rate(self.device_index)
                except RuntimeError:
                    raise RuntimeError("æ— æ³•é…ç½®ä»»ä½•å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡")
            else:
                raise
        
        # æ‰“å¼€éŸ³é¢‘æµ
        try:
            self.stream = self.p.open(
                format=self.format,
                channels=self.channels,
                rate=self.actual_sample_rate,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=self.chunk_size
            )
            
            logger.info(f"å½•éŸ³å·²å¯åŠ¨: {self.actual_sample_rate}Hz, {self.channels}å£°é“")
            if self.actual_sample_rate != self.target_sample_rate:
                logger.warning(f"æ³¨æ„: å®é™…é‡‡æ ·ç‡({self.actual_sample_rate}Hz) != ç›®æ ‡é‡‡æ ·ç‡({self.target_sample_rate}Hz), å°†è¿›è¡Œé‡é‡‡æ ·")
                
        except Exception as e:
            logger.error(f"æ‰“å¼€éŸ³é¢‘æµå¤±è´¥: {e}")
            raise
        
    def read(self):
        """è¯»å–ä¸€ä¸ªéŸ³é¢‘å—"""
        if not self.stream:
            raise RuntimeError("éŸ³é¢‘æµæœªå¯åŠ¨")
        
        data = self.stream.read(self.chunk_size, exception_on_overflow=False)
        audio_data = np.frombuffer(data, dtype=np.float32)
        
        # å¦‚æœéœ€è¦é‡é‡‡æ ·
        if self.actual_sample_rate != self.target_sample_rate:
            if LIBROSA_AVAILABLE:
                # ä½¿ç”¨librosaè¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·
                audio_data = librosa.resample(
                    audio_data, 
                    orig_sr=self.actual_sample_rate, 
                    target_sr=self.target_sample_rate
                )
            else:
                # ç®€å•é‡é‡‡æ ·
                ratio = self.target_sample_rate / self.actual_sample_rate
                new_length = int(len(audio_data) * ratio)
                if new_length > 0:
                    indices = np.linspace(0, len(audio_data) - 1, new_length)
                    audio_data = np.interp(indices, np.arange(len(audio_data)), audio_data)
        
        return audio_data
        
    @property
    def sample_rate(self):
        """è¿”å›ç›®æ ‡é‡‡æ ·ç‡"""
        return self.target_sample_rate
        
    def stop(self):
        """åœæ­¢å½•éŸ³"""
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        if self.p:
            self.p.terminate()
            self.p = None
        logger.info("å½•éŸ³å·²åœæ­¢")


class ASRWebSocketClient:
    """è¯­éŸ³è¯†åˆ«WebSocketå®¢æˆ·ç«¯"""
    
    def __init__(self, uri, sample_rate=16000):
        self.uri = uri
        self.sample_rate = sample_rate
        self.websocket = None
        
    async def connect(self):
        """è¿æ¥åˆ°WebSocketæœåŠ¡å™¨"""
        try:
            # åœ¨URIä¸­æ·»åŠ é‡‡æ ·ç‡å‚æ•°
            connect_uri = f"{self.uri}?samplerate={self.sample_rate}"
            self.websocket = await websockets.connect(connect_uri)
            logger.info(f"å·²è¿æ¥åˆ° {connect_uri}")
            return True
        except Exception as e:
            logger.error(f"è¿æ¥å¤±è´¥: {e}")
            return False
            
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.websocket:
            await self.websocket.close()
            self.websocket = None
            logger.info("å·²æ–­å¼€è¿æ¥")
            
    async def send_audio_chunk(self, audio_data):
        """å‘é€éŸ³é¢‘æ•°æ®å—"""
        if not self.websocket:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        # ç¡®ä¿æ•°æ®æ˜¯float32æ ¼å¼ï¼Œç„¶åè½¬æ¢ä¸ºint16å†å‘é€
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)
        
        # è½¬æ¢ä¸ºint16æ ¼å¼ï¼ˆæœåŠ¡å™¨æœŸå¾…çš„æ ¼å¼ï¼‰
        audio_int16 = (audio_data * 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()
        
        await self.websocket.send(audio_bytes)
        
    async def send_control_message(self, command):
        """å‘é€æ§åˆ¶æ¶ˆæ¯ï¼ˆç”¨äºoneshotæ¥å£ï¼‰"""
        if not self.websocket:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        control_msg = {
            "command": command
        }
        await self.websocket.send(json.dumps(control_msg))
        logger.debug(f"å‘é€æ§åˆ¶æ¶ˆæ¯: {command}")

    async def receive_result(self):
        """æ¥æ”¶è¯†åˆ«ç»“æœ"""
        if not self.websocket:
            return None
        
        try:
            response = await asyncio.wait_for(self.websocket.recv(), timeout=0.1)
            result = json.loads(response)
            return result
        except asyncio.TimeoutError:
            return None
        except json.JSONDecodeError as e:
            logger.warning(f"JSONè§£æé”™è¯¯: {e}, åŸå§‹æ•°æ®: {response}")
            return None
        except Exception as e:
            logger.error(f"æ¥æ”¶ç»“æœé”™è¯¯: {e}")
            return None
            
    async def process_file(self, audio_file_path):
        """å¤„ç†éŸ³é¢‘æ–‡ä»¶"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {audio_file_path}")
        
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        try:
            audio_data, file_sample_rate = load_audio_file(audio_file_path, self.sample_rate)
        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return
        
        if not await self.connect():
            return
            
        try:
            # åˆ›å»ºæ¥æ”¶ç»“æœçš„ä»»åŠ¡
            async def receive_results():
                results = []
                while True:
                    result = await self.receive_result()
                    if result is None:
                        await asyncio.sleep(0.01)
                        continue
                    
                    results.append(result)
                    if result.get('finished', False):
                        logger.info(f"âœ“ [å®Œæˆ] ç‰‡æ®µ {result.get('idx', 0)}: {result}")
                    else:
                        logger.info(f"â†’ [è¿›è¡Œä¸­] ç‰‡æ®µ {result.get('idx', 0)}: {result}")
                return results
            
            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡
            receive_task = asyncio.create_task(receive_results())
            
            # åˆ†å—å‘é€éŸ³é¢‘æ•°æ®
            chunk_size = self.sample_rate // 10  # 100ms å—
            total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size
            
            logger.info(f"å¼€å§‹å‘é€éŸ³é¢‘æ•°æ®ï¼Œå…± {total_chunks} ä¸ªå—ï¼Œæ¯å— {chunk_size} ä¸ªé‡‡æ ·ç‚¹")
            
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i+chunk_size]
                await self.send_audio_chunk(chunk)
                
                chunk_num = i // chunk_size + 1
                logger.debug(f"å·²å‘é€å— {chunk_num}/{total_chunks}")
                
                # æ¨¡æ‹Ÿå®æ—¶æµï¼Œé€‚å½“å»¶è¿Ÿ
                await asyncio.sleep(0.1)
            
            logger.info("éŸ³é¢‘å‘é€å®Œæˆï¼Œç­‰å¾…æœ€ç»ˆç»“æœ...")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´ä»¥æ¥æ”¶æ‰€æœ‰ç»“æœ
            await asyncio.sleep(3.0)
            receive_task.cancel()
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            await self.disconnect()
            
    async def process_microphone(self, duration=None):
        """å¤„ç†éº¦å…‹é£è¾“å…¥"""
        logger.info("å¼€å§‹éº¦å…‹é£è¯†åˆ«")
        
        if not await self.connect():
            return
            
        mic_stream = MicrophoneStream(self.sample_rate)
        
        try:
            mic_stream.start()
            
            # åˆ›å»ºæ¥æ”¶ç»“æœçš„ä»»åŠ¡
            async def receive_results():
                while True:
                    result = await self.receive_result()
                    if result is None:
                        await asyncio.sleep(0.01)
                        continue
                    
                    if result.get('finished', False):
                        logger.info(f"âœ“ [å®Œæˆ] ç‰‡æ®µ {result.get('idx', 0)}: {result.get('text', '')}")
                    else:
                        logger.info(f"â†’ [è¿›è¡Œä¸­] ç‰‡æ®µ {result.get('idx', 0)}: {result.get('text', '')}")
            
            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡
            receive_task = asyncio.create_task(receive_results())
            
            # å½•éŸ³å’Œå‘é€éŸ³é¢‘æ•°æ®
            start_time = time.time()
            chunk_count = 0
            
            if duration:
                logger.info(f"å½•éŸ³ {duration} ç§’...")
            else:
                logger.info("å¼€å§‹å½•éŸ³ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
            
            try:
                while True:
                    if duration and time.time() - start_time > duration:
                        break
                        
                    # è¯»å–éŸ³é¢‘å—
                    audio_chunk = mic_stream.read()
                    await self.send_audio_chunk(audio_chunk)
                    
                    chunk_count += 1
                    if chunk_count % 50 == 0:  # æ¯5ç§’æ‰“å°ä¸€æ¬¡
                        elapsed = time.time() - start_time
                        logger.debug(f"å·²å½•éŸ³ {elapsed:.1f} ç§’")
                    
                    await asyncio.sleep(0.01)  # å°å»¶è¿Ÿ
                    
            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·")
            
            logger.info("å½•éŸ³ç»“æŸï¼Œç­‰å¾…æœ€ç»ˆç»“æœ...")
            await asyncio.sleep(2.0)
            receive_task.cancel()
            
        except Exception as e:
            logger.error(f"éº¦å…‹é£å¤„ç†é”™è¯¯: {e}")
        finally:
            mic_stream.stop()
            await self.disconnect()

    async def process_file_oneshot(self, audio_file_path):
        """ä½¿ç”¨OneShotæ¥å£å¤„ç†éŸ³é¢‘æ–‡ä»¶"""
        logger.info(f"å¼€å§‹ä½¿ç”¨OneShotæ¥å£å¤„ç†æ–‡ä»¶: {audio_file_path}")
        
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        try:
            audio_data, file_sample_rate = load_audio_file(audio_file_path, self.sample_rate)
        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return
        
        # å°†URIä¿®æ”¹ä¸ºoneshotç«¯ç‚¹
        original_uri = self.uri
        if "/sttRealtime" in self.uri:
            self.uri = self.uri.replace("/sttRealtime", "/oneshot")
        elif not "/oneshot" in self.uri:
            # å¦‚æœURIä¸­æ²¡æœ‰å…·ä½“ç«¯ç‚¹ï¼Œæ·»åŠ oneshot
            self.uri = self.uri.rstrip('/') + '/oneshot'
        
        if not await self.connect():
            self.uri = original_uri  # æ¢å¤åŸURI
            return
            
        try:
            # åˆ›å»ºæ¥æ”¶ç»“æœçš„ä»»åŠ¡
            async def receive_results():
                results = []
                while True:
                    result = await self.receive_result()
                    if result is None:
                        await asyncio.sleep(0.01)
                        continue
                    
                    results.append(result)
                    result_type = result.get('type', 'unknown')
                    
                    if result_type == 'status':
                        status = result.get('status', '')
                        logger.info(f"ğŸ“Ÿ [çŠ¶æ€] {status}")
                    elif result_type == 'result':
                        text = result.get('text', '')
                        lang = result.get('lang', 'auto')
                        emotion = result.get('emotion', '')
                        event = result.get('event', '')
                        timestamps = result.get('timestamps', [])
                        tokens = result.get('tokens', [])
                        
                        logger.info(f"âœ… [è¯†åˆ«ç»“æœ] æ–‡æœ¬: {text}")
                        if lang != 'auto':
                            logger.info(f"    è¯­è¨€: {lang}")
                        if emotion:
                            logger.info(f"    æƒ…æ„Ÿ: {emotion}")
                        if event:
                            logger.info(f"    äº‹ä»¶: {event}")
                        if timestamps:
                            logger.info(f"    æ—¶é—´æˆ³: {len(timestamps)}ä¸ª")
                        if tokens:
                            logger.info(f"    è¯å…ƒ: {', '.join(tokens)}")
                    elif result_type == 'error':
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"âŒ [é”™è¯¯] {error_msg}")
                    else:
                        logger.info(f"ğŸ“¨ [å…¶ä»–æ¶ˆæ¯] {result}")
                return results
            
            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡
            receive_task = asyncio.create_task(receive_results())
            
            # å‘é€å¼€å§‹å½•éŸ³å‘½ä»¤
            await self.send_control_message("start")
            await asyncio.sleep(0.5)  # ç­‰å¾…æœåŠ¡å™¨å‡†å¤‡
            
            # åˆ†å—å‘é€éŸ³é¢‘æ•°æ®
            chunk_size = self.sample_rate # // 10  # 100ms å—
            total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size
            
            logger.info(f"å¼€å§‹å‘é€éŸ³é¢‘æ•°æ®ï¼Œå…± {total_chunks} ä¸ªå—ï¼Œæ¯å— {chunk_size} ä¸ªé‡‡æ ·ç‚¹")
            
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i+chunk_size]
                await self.send_audio_chunk(chunk)
                
                chunk_num = i // chunk_size + 1
                logger.debug(f"å·²å‘é€å— {chunk_num}/{total_chunks}")
                
                # é€‚å½“å»¶è¿Ÿæ¨¡æ‹Ÿå®æ—¶å‘é€
                await asyncio.sleep(0.05)
            
            logger.info("éŸ³é¢‘å‘é€å®Œæˆï¼Œå‘é€åœæ­¢å‘½ä»¤...")
            
            # å‘é€åœæ­¢å½•éŸ³å‘½ä»¤ï¼Œå¼€å§‹å¤„ç†
            await self.send_control_message("stop")
            
            # ç­‰å¾…å¤„ç†ç»“æœ
            logger.info("ç­‰å¾…è¯†åˆ«ç»“æœ...")
            await asyncio.sleep(5.0)
            receive_task.cancel()
            
        except Exception as e:
            logger.error(f"OneShotå¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            await self.disconnect()
            self.uri = original_uri  # æ¢å¤åŸURI

    async def process_microphone_oneshot(self, duration=10):
        """ä½¿ç”¨OneShotæ¥å£å¤„ç†éº¦å…‹é£è¾“å…¥"""
        logger.info(f"å¼€å§‹ä½¿ç”¨OneShotæ¥å£è¿›è¡Œéº¦å…‹é£è¯†åˆ«ï¼ˆå½•éŸ³{duration}ç§’ï¼‰")
        
        # å°†URIä¿®æ”¹ä¸ºoneshotç«¯ç‚¹
        original_uri = self.uri
        if "/sttRealtime" in self.uri:
            self.uri = self.uri.replace("/sttRealtime", "/oneshot")
        elif not "/oneshot" in self.uri:
            # å¦‚æœURIä¸­æ²¡æœ‰å…·ä½“ç«¯ç‚¹ï¼Œæ·»åŠ oneshot
            self.uri = self.uri.rstrip('/') + '/oneshot'
        
        if not await self.connect():
            self.uri = original_uri  # æ¢å¤åŸURI
            return
            
        mic_stream = MicrophoneStream(self.sample_rate)
        
        try:
            mic_stream.start()
            
            # åˆ›å»ºæ¥æ”¶ç»“æœçš„ä»»åŠ¡
            async def receive_results():
                while True:
                    result = await self.receive_result()
                    if result is None:
                        await asyncio.sleep(0.01)
                        continue
                    
                    result_type = result.get('type', 'unknown')
                    
                    if result_type == 'status':
                        status = result.get('status', '')
                        logger.info(f"ğŸ“Ÿ [çŠ¶æ€] {status}")
                    elif result_type == 'result':
                        text = result.get('text', '')
                        lang = result.get('lang', 'auto')
                        emotion = result.get('emotion', '')
                        event = result.get('event', '')
                        timestamps = result.get('timestamps', [])
                        
                        logger.info(f"âœ… [è¯†åˆ«ç»“æœ] æ–‡æœ¬: {text}")
                        if lang != 'auto':
                            logger.info(f"    è¯­è¨€: {lang}")
                        if emotion:
                            logger.info(f"    æƒ…æ„Ÿ: {emotion}")
                        if event:
                            logger.info(f"    äº‹ä»¶: {event}")
                        if timestamps:
                            logger.info(f"    æ—¶é—´æˆ³: {len(timestamps)}ä¸ª")
                    elif result_type == 'error':
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"âŒ [é”™è¯¯] {error_msg}")
                    else:
                        logger.info(f"ğŸ“¨ [å…¶ä»–æ¶ˆæ¯] {result}")
            
            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡
            receive_task = asyncio.create_task(receive_results())
            
            # å‘é€å¼€å§‹å½•éŸ³å‘½ä»¤
            await self.send_control_message("start")
            await asyncio.sleep(0.5)  # ç­‰å¾…æœåŠ¡å™¨å‡†å¤‡
            
            # å½•éŸ³å’Œå‘é€éŸ³é¢‘æ•°æ®
            start_time = time.time()
            chunk_count = 0
            
            logger.info(f"å¼€å§‹å½•éŸ³ {duration} ç§’...")
            
            try:
                while time.time() - start_time < duration:
                    # è¯»å–éŸ³é¢‘å—
                    audio_chunk = mic_stream.read()
                    await self.send_audio_chunk(audio_chunk)
                    
                    chunk_count += 1
                    elapsed = time.time() - start_time
                    if chunk_count % 20 == 0:  # æ¯2ç§’æ‰“å°ä¸€æ¬¡
                        remaining = duration - elapsed
                        logger.debug(f"å½•éŸ³ä¸­... å·²å½• {elapsed:.1f}s, å‰©ä½™ {remaining:.1f}s")
                    
                    await asyncio.sleep(0.01)  # å°å»¶è¿Ÿ
                    
            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæå‰ç»“æŸå½•éŸ³")
            
            logger.info("å½•éŸ³ç»“æŸï¼Œå‘é€åœæ­¢å‘½ä»¤...")
            
            # å‘é€åœæ­¢å½•éŸ³å‘½ä»¤ï¼Œå¼€å§‹å¤„ç†
            await self.send_control_message("stop")
            
            # ç­‰å¾…å¤„ç†ç»“æœ
            logger.info("ç­‰å¾…è¯†åˆ«ç»“æœ...")
            await asyncio.sleep(5.0)
            receive_task.cancel()
            
        except Exception as e:
            logger.error(f"OneShotéº¦å…‹é£å¤„ç†é”™è¯¯: {e}")
        finally:
            mic_stream.stop()
            await self.disconnect()
            self.uri = original_uri  # æ¢å¤åŸURI


async def main():
    parser = argparse.ArgumentParser(description="è¯­éŸ³è¯†åˆ«WebSocketå®¢æˆ·ç«¯")
    parser.add_argument("--server", default="ws://localhost:8000/sttRealtime", 
                       help="WebSocketæœåŠ¡å™¨åœ°å€ (é»˜è®¤: ws://localhost:8000/sttRealtime)")
    parser.add_argument("--sample-rate", type=int, default=16000,
                       help="éŸ³é¢‘é‡‡æ ·ç‡ (é»˜è®¤: 16000)")
    
    # è¯†åˆ«æ¨¡å¼é€‰æ‹©
    parser.add_argument("--mode", choices=["streaming", "oneshot"], default="streaming",
                       help="è¯†åˆ«æ¨¡å¼: streaming(æµå¼) æˆ– oneshot(ä¸€å¥è¯) (é»˜è®¤: streaming)")
    
    # éŸ³é¢‘æºé€‰æ‹©
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--file", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    group.add_argument("--mic", action="store_true", help="ä½¿ç”¨éº¦å…‹é£")
    
    # éº¦å…‹é£é€‰é¡¹
    parser.add_argument("--duration", type=int, 
                       help="å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚æµå¼æ¨¡å¼ï¼šä¸æŒ‡å®šåˆ™æŒç»­å½•éŸ³ç›´åˆ°Ctrl+Cï¼›OneShotæ¨¡å¼ï¼šé»˜è®¤10ç§’")
    
    args = parser.parse_args()
    
    client = ASRWebSocketClient(args.server, args.sample_rate)
    
    if args.file:
        # æ–‡ä»¶æ¨¡å¼
        if args.mode == "oneshot":
            await client.process_file_oneshot(args.file)
        else:
            await client.process_file(args.file)
    elif args.mic:
        # éº¦å…‹é£æ¨¡å¼
        if args.mode == "oneshot":
            duration = args.duration if args.duration else 10  # OneShoté»˜è®¤10ç§’
            await client.process_microphone_oneshot(duration)
        else:
            await client.process_microphone(args.duration)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
